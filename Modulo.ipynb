{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "El **objetivo del presente trabajo es desarrollar un prototipo de modelo de Machine Learning** para Zyfra, empresa especializada en soluciones de eficiencia para la industria pesada. El modelo permitirá **predecir la cantidad de oro extraído del mineral**, utilizando datos de extracción y purificación, con el fin de optimizar la producción y eliminar parámetros no rentables.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparación de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apertura y examinación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de paquetes, librerías y módulos\n",
    "\n",
    "# Librerías para manipulación de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Librerías para visualización\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Librerías de machine learning - modelos\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "# Librerías de machine learning - evaluación y validación\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn import metrics as met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datos\n",
    "\n",
    "try:\n",
    "    data = pd.read_csv('gold_recovery_full.csv')\n",
    "    data_train = pd.read_csv('gold_recovery_train.csv')\n",
    "    data_test = pd.read_csv('gold_recovery_test.csv')\n",
    "except:\n",
    "    data = pd.read_csv('/datasets/gold_recovery_full.csv')\n",
    "    data_train = pd.read_csv('/datasets/gold_recovery_train.csv')\n",
    "    data_test = pd.read_csv('/datasets/gold_recovery_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploración del df completo\n",
    "\n",
    "data.info()\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Exploración del df de entrenamiento\n",
    "\n",
    "data_train.info()\n",
    "display(data_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Exploración del df de prueba\n",
    "\n",
    "data_test.info()\n",
    "display(data_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se encontraron columnas faltantes en este df. Se añadirán posteriormente en el procesamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Búsqueda de filas duplicadas en los dfs\n",
    "\n",
    "print('Filas duplicadas: ', \n",
    "      data.duplicated().sum(),\n",
    "      data_train.duplicated().sum(), \n",
    "      data_test.duplicated().sum()\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Según la descripción del proyecto, el conjunto de datos original (22,716 registros) incluye los valores combinados de los conjuntos de entrenamiento y prueba, con 16,860 y 5,856 registros respectivamente. \n",
    "\n",
    "Al analizar el tamaño de cada conjunto (filas y columnas), observamos que todas las columnas son de tipo numérico flotante, excepto la columna `date`, que actualmente es de tipo objeto y debe convertirse a tipo datetime para facilitar su manejo.\n",
    "\n",
    "Todas las columnas numéricas tienen tipo de dato `float64`. Se identificaron valores faltantes en varias columnas; sin embargo, el tratamiento de estos datos faltantes y la eliminación de duplicados se abordarán en etapas posteriores del proyecto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revisión del cálculo de recuperación\n",
    "\n",
    "$$\n",
    "Recuperación = \\frac { C * (F-T)} { F * (C - T)} * 100\\%\n",
    "$$\n",
    "\n",
    "- C = la proporción de oro en el concentrado justo después de la flotación (`rougher.output.concentrate_au`) o después de la purificación (`final.output.concentrate_au`)\n",
    "- F = la proporción de oro en la alimentación antes de la flotación (`rougher.input.feed_au`) o en el concentrado justo después de la flotación (`primary_cleaner.output.concentrate_au`)\n",
    "- T = la proporción de oro en las colas rougher justo después de la flotación (`rougher.output.tail_au`) o después de la purificación (`secundary_cleanear.output.tail_au`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para el cálculo de la recuperación de concentrados\n",
    "\n",
    "def recovery(data, concentrate):\n",
    "    if concentrate == 'rougher':\n",
    "        c = data['rougher.output.concentrate_au']\n",
    "        f = data['rougher.input.feed_au']\n",
    "        t = data['rougher.output.tail_au']\n",
    "    elif concentrate == 'final':\n",
    "        c = data['final.output.concentrate_au']\n",
    "        f = data['primary_cleaner.output.concentrate_au']\n",
    "        t = data['secundary_cleanear.output.tail_au']\n",
    "\n",
    "    recovery = ((c * (f - t)) / (f * (c - t))) * 100\n",
    "    return recovery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos desarrollado una función para calcular la recuperación del *concentrado rougher* y del *concentrado final*. Utilizaremos esta función para verificar la precisión del cálculo de recuperación rougher en la característica `rougher.output.recovery` del conjunto de entrenamiento. Posteriormente, evaluaremos el desempeño mediante el cálculo del error absoluto medio (EAM) entre nuestros resultados y los valores reales de la característica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo de la recuperación del concentrado rougher\n",
    "\n",
    "# Guardado de los datos de entrenamiento sin NaN de la columna \"rougher.output.recovery\"\n",
    "data_train_dep = data_train.dropna(subset=['rougher.output.recovery'])\n",
    "concentrate = ['rougher', 'final']\n",
    "\n",
    "rougher_recovery_calculate = recovery(data_train_dep, concentrate[0])\n",
    "rougher_recovery_calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo del Error Absoluto Medio (EAM)\n",
    "\n",
    "eam = mean_absolute_error(data_train_dep['rougher.output.recovery'],\n",
    "                          rougher_recovery_calculate)\n",
    "\n",
    "print('EAM de la recuperación del concentrado rougher', eam)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La recuperación del *concentrado rougher* en el conjunto de entrenamiento es precisa, con un EAM cercano a cero (9.3×10⁻¹⁵). Esto indica que los valores calculados coinciden prácticamente con los datos originales, confirmando la validez del modelo para esta variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de características no disponibles en el conjunto de prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora exploraremos las características no disponibles en el conjunto de prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Búsqueda de columnas faltantes\n",
    "missing_columns = list(set(data.columns) - set(data_test.columns))\n",
    "missing_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se identificó que el conjunto de datos de prueba presenta 34 columnas faltantes, incluyendo las variables objetivo `rougher.output.recovery` y `final.output.recovery`. Además, faltan 4 parámetros correspondientes a la etapa de `calculation` y todos los 30 parámetros de la etapa `output`. Aquí se detallan las columnas faltantes por cada etapa del proceso:\n",
    "\n",
    "*Etapa `rougher`, parámetros `calculation` y `output`*\n",
    "- `'rougher.calculation.sulfate_to_au_concentrate'`\n",
    "- `'rougher.calculation.floatbank10_sulfate_to_au_feed'`\n",
    "- `'rougher.calculation.floatbank11_sulfate_to_au_feed'`\n",
    "- `'rougher.calculation.au_pb_ratio'`\n",
    "- `'rougher.output.concentrate_ag'`\n",
    "- `'rougher.output.concentrate_pb'`\n",
    "- `'rougher.output.concentrate_sol'`\n",
    "- `'rougher.output.concentrate_au'`\n",
    "- **`'rougher.output.recovery'`**\n",
    "- `'rougher.output.tail_ag'`\n",
    "- `'rougher.output.tail_pb'`\n",
    "- `'rougher.output.tail_sol'`\n",
    "- `'rougher.output.tail_au'`\n",
    "\n",
    "*Etapa `primary_cleaner`, parámetro `output`*\n",
    "- `'primary_cleaner.output.concentrate_ag'`\n",
    "- `'primary_cleaner.output.concentrate_pb'`\n",
    "- `'primary_cleaner.output.concentrate_sol'`\n",
    "- `'primary_cleaner.output.concentrate_au'`\n",
    "- `'primary_cleaner.output.tail_ag'`\n",
    "- `'primary_cleaner.output.tail_pb'`\n",
    "- `'primary_cleaner.output.tail_sol'`\n",
    "- `'primary_cleaner.output.tail_au'`\n",
    "\n",
    "*Etapa `secondary_cleaner`, parámetro `output`*\n",
    "- `'secondary_cleaner.output.tail_ag'`\n",
    "- `'secondary_cleaner.output.tail_pb'`\n",
    "- `'secondary_cleaner.output.tail_sol'`\n",
    "- `'secondary_cleaner.output.tail_au']`\n",
    "  \n",
    "*Etapa `final`, parámetro `output`*\n",
    "- `'final.output.concentrate_ag'`\n",
    "- `'final.output.concentrate_pb'`\n",
    "- `'final.output.concentrate_sol'`\n",
    "- `'final.output.concentrate_au'`\n",
    "- **`'final.output.recovery'`**\n",
    "- `'final.output.tail_ag'`\n",
    "- `'final.output.tail_pb'`\n",
    "- `'final.output.tail_sol'`\n",
    "- `'final.output.tail_au'`\n",
    "  \n",
    "Estas características corresponden a valores obtenidos en distintas etapas del proceso de refinación posterior a la flotación. Específicamente, representan concentrados y mediciones de diversos materiales y subproductos antes y después de las fases de purificación.\n",
    "\n",
    "Se incorporarán las variables objetivo al conjunto de prueba para garantizar la integridad estructural durante la validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se utiliza 'date' como índice para asegurar alineación\n",
    "data_indexed = data.set_index('date')\n",
    "data_test_indexed = data_test.set_index('date')\n",
    "\n",
    "# Se añaden las columnas faltantes de data a data_test sobre el índice ('date')\n",
    "data_test_updated = data_test_indexed.join(data_indexed[missing_columns], how='left')\n",
    "\n",
    "# Columnas presentes en data_test_updated (original + añadidas)\n",
    "cols = data_test_updated.columns\n",
    "\n",
    "# Ordenar columnas de acuerdo a data\n",
    "ordered_cols = [col for col in data_indexed.columns if col in cols]\n",
    "data_test_updated = data_test_updated[ordered_cols]\n",
    "data_test_updated = data_test_updated.reset_index()\n",
    "\n",
    "# Regresa a su nombre original\n",
    "data_test = data_test_updated\n",
    "\n",
    "data_test.info()\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columna de fechas\n",
    "\n",
    "Para facilitar su uso en operaciones posteriores, convertiremos la columna de fechas al tipo de dato `datetime`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambio a formato datetime\n",
    "data['date'] = pd.to_datetime(data['date'], format='%Y-%m-%d %H:%M:%S')\n",
    "data_train['date'] = pd.to_datetime(data_train['date'], format='%Y-%m-%d %H:%M:%S')\n",
    "data_test['date'] = pd.to_datetime(data_test['date'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "data[['date']].info()\n",
    "display(data[['date']].head(3))\n",
    "\n",
    "data_train[['date']].info()\n",
    "display(data_train[['date']].head(3))\n",
    "\n",
    "data_test[['date']].info()\n",
    "display(data_test[['date']].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores faltantes\n",
    "\n",
    "Primero, evaluaremos la cantidad de valores faltantes en los conjuntos de datos antes de definir la estrategia para su tratamiento. Cabe destacar que el conjunto de datos original es la combinación de los conjuntos de entrenamiento y prueba, por lo que podría existir solapamiento en los valores faltantes entre estos subconjuntos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de filas con valores faltantes en los df\n",
    "print('Número de filas con valores faltantes en el conjunto original: ', data[data.isna().sum(axis=1) > 0].shape)\n",
    "print('Número de filas con valores faltantes en el conjunto de entrenamiento: ', data_train[data_train.isna().sum(axis=1) > 0].shape)\n",
    "print('Número de filas con valores faltantes en el conjunto de prueba: ', data_test[data_test.isna().sum(axis=1) > 0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listado de columnas con valores faltantes\n",
    "print(data.columns[data.isna().any()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se identificaron 6.622 registros con al menos un valor faltante en el conjunto de datos (29.2% del total de 22.716 entradas). Considerando la naturaleza temporal de los datos y la correlación entre mediciones cercanas, se implementará la siguiente estrategia:\n",
    "\n",
    "- Eliminar filas con valores faltantes en las variables objetivo (`rougher.output.recovery` y `final.output.recovery`).\n",
    "\n",
    "- Agrupar los datos por fecha (`dt.date`) y aplicar el método de `forward fill` para imputar valores faltantes restantes.\n",
    "\n",
    "- Eliminar registros remanentes con valores faltantes tras la imputación.\n",
    "\n",
    "Para garantizar consistencia y eficiencia, este proceso se automatizará mediante la función `fill_and_drop()`, aplicable a cualquier dataframe del proyecto.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para rellenado de fechas\n",
    "def fill_and_drop(df):\n",
    "    df = df.groupby(df['date'].dt.date).ffill()\n",
    "    \n",
    "    return df.dropna()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificación de filas con objetivos ausentes\n",
    "nan_target_rows = data[data['rougher.output.recovery'].isna() | data['final.output.recovery'].isna()]\n",
    "\n",
    "# Eliminar esas filas de los conjuntos principal, de entrenamiento y prueba según fechas coincidentes\n",
    "data.drop(nan_target_rows.index, inplace=True)\n",
    "data_train.drop((data.query('date in @nan_target_rows.date')).index, inplace=True)\n",
    "data_test.drop((data.query('date in @nan_target_rows.date')).index, inplace=True)\n",
    "\n",
    "# Limpiar los conjuntos aplicando ffill y eliminando valores faltantes restantes\n",
    "data = fill_and_drop(data)\n",
    "data_train = fill_and_drop(data_train)\n",
    "data_test = fill_and_drop(data_test)\n",
    "\n",
    "print('Número de filas con valores faltantes en el conjunto original: ', data[data.isna().sum(axis=1) > 0].shape)\n",
    "print('Número de filas con valores faltantes en el conjunto de entrenamiento: ', data_train[data_train.isna().sum(axis=1) > 0].shape)\n",
    "print('Número de filas con valores faltantes en el conjunto de prueba: ', data_test[data_test.isna().sum(axis=1) > 0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificación de valores duplicados\n",
    "\n",
    "Se analizará el conjunto de datos original para identificar posibles valores duplicados y, en caso de encontrarlos, se eliminarán las entradas correspondientes para garantizar la calidad y consistencia de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Número de duplicados: ', data.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No se detectaron valores duplicados en el conjunto de datos original, por lo que se garantiza que tampoco existen en los subconjuntos de entrenamiento y prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cambio en la concentración de metales durante la etapa de purificación\n",
    "\n",
    "A continuación se observará el cambio en la concentración de oro, plata y plomo (Au, Ag, Pb) en función de la etapa de purificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracción de datos de cada metal\n",
    "\n",
    "au = data[['date', 'primary_cleaner.output.concentrate_au', 'secondary_cleaner.output.tail_au']].set_index(keys='date')  # Oro\n",
    "ag = data[['date', 'primary_cleaner.output.concentrate_ag', 'secondary_cleaner.output.tail_ag']].set_index(keys='date')  # Plata\n",
    "pb = data[['date', 'primary_cleaner.output.concentrate_pb', 'secondary_cleaner.output.tail_pb']].set_index(keys='date')  # Plomo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para descripción y visualización de concentraciones\n",
    "\n",
    "def concentration(metal):\n",
    "    \n",
    "    summary = metal.describe().loc[['count', 'mean', 'std', 'min', '50%', 'max']]\n",
    "    display(summary.round(2).style.format(\"{:,.2f}\"))\n",
    "\n",
    "    # Visualización del cambio de concentración de oro\n",
    "\n",
    "    plt.figure(figsize=(15, 4))\n",
    "    plt.plot(metal.index, \n",
    "             metal.iloc[:, 0], \n",
    "             label='Primera etapa')\n",
    "    \n",
    "    plt.plot(metal.index, \n",
    "             metal.iloc[:, 1], # Segunda columna\n",
    "             label='Segunda etapa')\n",
    "                \n",
    "    plt.title('Cambio de concentración de oro según la etapa de purificación')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Fecha')\n",
    "    plt.ylabel('Concentración \\n')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparación de las concentraciones de oro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparación de las concentraciones de oro\n",
    "\n",
    "concentration(au)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La concentración de oro es mayor en la primera etapa de limpieza que en la segunda etapa de limpieza. La mediana está cerca de la media en ambas etapas, lo que indica una distribución relativamente simétrica sin sesgos extremos. La concentración media de oro en la primera etapa es aproximadamente 7 veces mayor que en la segunda etapa (32.08 vs 4.39 g/t), lo que indica que la mayor parte del oro valioso se concentra en la salida del limpiador primario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparación de las concentraciones de plata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparación de las concentraciones de plata\n",
    "\n",
    "concentration(ag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La concentración media de plata aumenta notablemente de la primera etapa (8.56) a la segunda etapa (14.67), lo que indica que el proceso de purificación está incrementando la concentración de plata en el material tratado. La desviación estándar en la segunda etapa (3.93) es casi el doble que en la primera (2.02), lo que sugiere que la concentración de oro en la segunda etapa es más variable. Esto puede deberse a fluctuaciones en el proceso o a la heterogeneidad del material tratado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparación de las concentraciones de plomo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparación de las concentraciones de plomo\n",
    "\n",
    "concentration(pb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El proceso de purificación reduce notablemente la concentración de plomo desde la primera a la segunda etapa (9.81 vs 5.65), lo que indica una efectiva eliminación o transformación del plomo durante el proceso. La consistencia en la cantidad de datos y la similitud en la dispersión sugieren que esta tendencia es estable y confiable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparación de las distribución del tamaño de las partículas de la alimentación en el conjunto de entrenamiento y en el conjunto de prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizaremos y compararemos las distribuciones del tamaño de las partículas de alimentación (`feed size`) en los conjuntos de entrenamiento y prueba, con el objetivo de evaluar la representatividad de los datos y la validez del proceso de evaluación del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columnas relacionadas con 'feed size'\n",
    "\n",
    "feed_size = data_train.columns[data_train.columns.str.contains(\n",
    "    'feed_size')].tolist()\n",
    "print(feed_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primera etapa del proceso de limpieza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Información respecto a 'primary_cleaner.input.feed_size'\n",
    "\n",
    "desc_primary_train = data_train[feed_size[0]].describe()\n",
    "desc_primary_test = data_test[feed_size[0]].describe()\n",
    "\n",
    "# Combinación en df\n",
    "description_primary = pd.DataFrame({\n",
    "    'Entrenamiento': desc_primary_train,\n",
    "    'Prueba': desc_primary_test})\n",
    "\n",
    "display(description_primary.round(2).style.format(\"{:,.2f}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train[feed_size[0]].hist(figsize=(\n",
    "    6, 4), density=True, ec='black', alpha=0.6, bins=30, range=(4, 12), label='Conjunto de entrenamiento')\n",
    "data_test[feed_size[0]].hist(figsize=(\n",
    "    6, 4), density=True, ec='black', alpha=0.6, bins=30, range=(4, 12), label='Conjunto de prueba')\n",
    "plt.title('Comparación de \"primary_cleaner.input.feed_size\"')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las medias (7.35 vs 7.28) y medianas (7.30 vs 7.25) entre ambos conjuntos son muy cercanas, lo que indica que la distribución central de los datos es consistente entre entrenamiento y prueba. Ambas muestras tienen la misma desviación estándar (0.60), lo que sugiere que la dispersión o variabilidad de los datos es similar en ambos conjuntos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flotación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'rougher.input.feed_size'\n",
    "\n",
    "desc_rougher_train = data_train[feed_size[1]].describe()\n",
    "desc_rougher_test = data_test[feed_size[1]].describe()\n",
    "\n",
    "# Combinación en df\n",
    "description_rougher = pd.DataFrame({\n",
    "    'Entrenamiento': desc_rougher_train,\n",
    "    'Prueba': desc_rougher_test})\n",
    "\n",
    "display(description_rougher.round(2).style.format(\"{:,.2f}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de \"rougher.input.feed_size\"\n",
    "data_train[feed_size[1]].hist(figsize=(\n",
    "    6, 4), density=True, ec='black', alpha=0.6, bins=24, range=(0, 150), label='Conjunto de entrenamiento')\n",
    "data_test[feed_size[1]].hist(figsize=(\n",
    "    6, 4), density=True, ec='black', alpha=0.6, bins=24, range=(0, 150), label='Conjunto de prueba')\n",
    "plt.title('Comparación de \"rougher.input.feed_size\"')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las medias (57.80 vs 55.58) y medianas (53.88 vs 50.63) son muy cercanas, lo que indica que **la distribución central de los datos es similar en ambos conjuntos**. La desviación estándar es mayor en el conjunto de entrenamiento (22.05) que en el de prueba (18.18), sugiriendo que el entrenamiento contiene una mayor dispersión de valores. Esto puede deberse a la mayor cantidad de datos o a la presencia de valores más extremos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En términos generales, **sí es posible realizar una evaluación correcta del modelo** con los conjuntos `primary_cleaner` y `rougher`, ya que ambos conjuntos tienen un tamaño suficiente para garantizar estabilidad estadística, y las distribuciones de los datos de entrenamiento y prueba son comparables y representativas. Esto permite que las métricas de desempeño reflejen con precisión la capacidad del modelo para generalizar a datos no vistos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concentraciones totales de metales en las diferentes etapas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se observarán las concentraciones de todos los metales en las distintas etapas del proceso (*rougher input*, *rougher output* y *final output*). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rougher_input_labels = ['rougher.input.feed_au', \n",
    "                        'rougher.input.feed_ag', \n",
    "                        'rougher.input.feed_pb']\n",
    "rougher_output_labels = ['rougher.output.concentrate_au', \n",
    "                         'rougher.output.concentrate_ag', \n",
    "                         'rougher.output.concentrate_pb']\n",
    "final_output_labels = ['final.output.concentrate_au', \n",
    "                       'final.output.concentrate_ag', \n",
    "                       'final.output.concentrate_pb']\n",
    "\n",
    "combined_labels = rougher_input_labels + rougher_output_labels + final_output_labels\n",
    "\n",
    "# Creación de df con columnas relevantes\n",
    "concentration = data[combined_labels]\n",
    "display(concentration.describe().style.format(\"{:,.2f}\"))\n",
    "print()\n",
    "\n",
    "# Visualización de diagramas de caja\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.boxplot([concentration[col].dropna() for col in combined_labels], labels=combined_labels)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.xlabel('Etapa.Metal')\n",
    "plt.ylabel('Valores')\n",
    "plt.title('Diagramas de caja de la concentración de metales')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir del análisis de los diagramas de caja, se evidencia la presencia significativa de valores atípicos en las variables estudiadas. En consecuencia, se procederá a realizar un análisis detallado mediante la elaboración de una tabla que cuantifique y caracterice los valores atípicos, tanto bajos como altos, para cada metal en las distintas etapas del proceso. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_summary(df, columns):\n",
    "    summary = []\n",
    "    for col in columns:\n",
    "        \n",
    "        # Cálculo de Q1, Q3, IQR\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        # Umbrales de valores atípicos\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        # Identificación de valores atípicos\n",
    "        low_outliers = df[df[col] < lower_bound][col]\n",
    "        high_outliers = df[df[col] > upper_bound][col]\n",
    "        \n",
    "        # Resumen\n",
    "        summary.append({\n",
    "            'Etapa': col,\n",
    "            'Valores atípicos bajos': low_outliers.count(),\n",
    "            'Mínimo bajo': low_outliers.min() if not low_outliers.empty else None,\n",
    "            'Máximo bajo': low_outliers.max() if not low_outliers.empty else None,\n",
    "            'Valores atípicos altos': high_outliers.count(),\n",
    "            'Mínimo alto': high_outliers.min() if not high_outliers.empty else None,\n",
    "            'Máximo alto': high_outliers.max() if not high_outliers.empty else None\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(summary)\n",
    "\n",
    "outlier_summary(data, combined_labels).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El análisis de los valores en las columnas indicadas muestra que existen tanto valores atípicos bajos como altos, aunque la cantidad y magnitud varían significativamente según la variable. Por ejemplo, en las variables de entrada como `rougher.input.feed_au` y `rougher.input.feed_ag` predominan outliers bajos, mientras que en `rougher.input.feed_pb` hay tanto valores atípicos bajos como un número considerable de altos (106). En las salidas del proceso (`rougher.output.concentrate` y `final.output.concentrate`) hay una alta cantidad de valores atípicos bajos y también varios valores atípicos altos, especialmente en `final.output.concentrate_ag` con 415 altos, y en `final.output.concentrate_au` con 1016 bajos.\n",
    "\n",
    "Considerando que algunos valores atípicos pueden corresponder a datos válidos que reflejan la variabilidad intrínseca del proceso o eventos relevantes, no se procederá a eliminar la totalidad de estos. En su lugar, se enfocará la atención únicamente en los valores atípicos extremadamente bajos, específicamente aquellos comprendidos entre 0 y 0.8, que representan el rango máximo de outliers inferiores en la variable `rougher.input.feed_pb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Número de casos con valor < 0.5 en la etapa \"rougher_input\": ',\n",
    "      len(data[data[rougher_input_labels].sum(axis=1) < 0.8]))\n",
    "print('Número de casos con valor < 0.5 en la etapa \"rougher_output\": ',\n",
    "      len(data[data[rougher_output_labels].sum(axis=1) < 0.8]))\n",
    "print('Número de casos con valor < 0.5 en la etapa \"final_output\": ',\n",
    "      len(data[data[final_output_labels].sum(axis=1) < 0.8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observación del resto de información en las filas con valores atípicos\n",
    "\n",
    "# Recopilación de las filas con valores atípicos\n",
    "outliers_rougher_input = data[rougher_input_labels].sum(axis=1) < 0.8\n",
    "outliers_rougher_output = data[rougher_output_labels].sum(axis=1) < 0.8\n",
    "outliers_final_output = data[final_output_labels].sum(axis=1) < 0.8\n",
    "\n",
    "# Combinación de la información recopilada en un df\n",
    "combined_outliers = outliers_rougher_input | outliers_rougher_output | outliers_final_output\n",
    "outliers = data.loc[combined_outliers]\n",
    "\n",
    "display(outliers.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al observar el conjunto de datos, se identificó que en las observaciones donde se presentan los valores atípicos señalados, las demás variables asociadas mantienen valores dentro de rangos esperados y consistentes. Esto sugiere que dichos valores atípicos corresponden a anomalías puntuales. En consecuencia, se procederá a la eliminación de estos registros en las tablas de concentración de metales, con el fin de preservar la integridad y calidad del análisis posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descripción del df tras eliminar valores menores a 0.8\n",
    "concentration_clean = concentration.loc[(concentration >= 0.8).all(axis=1)]\n",
    "\n",
    "concentration_clean.describe().style.format(\"{:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asimismo, los eliminaremos de los conjuntos de entrenamiento y prueba, para evitar que afecten negativamente los resultados posteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpieza del conjunto original, de entrenamiento y de prueba\n",
    "\n",
    "# Identificación de valores anómalos\n",
    "\n",
    "reference = data[(data[rougher_input_labels].sum(axis=1) < 0.8) |\n",
    "                 (data[rougher_output_labels].sum(axis=1) < 0.8) |\n",
    "                 (data[final_output_labels].sum(axis=1) < 0.8)]['date']\n",
    "\n",
    "# Limpieza de datos\n",
    "\n",
    "data_clean = data.drop(data.query('date in @reference').index)\n",
    "data_train_clean = data_train.drop(data_train.query('date in @reference').index)\n",
    "data_test_clean = data_test.drop(data_test.query('date in @reference').index)\n",
    "\n",
    "# Visualización de resultados\n",
    "\n",
    "result_df = pd.DataFrame(\n",
    "    {\n",
    "        'Original': [len(data),len(data_train),len(data_test)],\n",
    "        'Limpio': [len(data_clean), len(data_train_clean), len(data_test_clean)]\n",
    "    },\n",
    "    index=['Original', 'Entrenamiento', 'Prueba']\n",
    ")\n",
    "result_df.index.name = 'Conjunto'\n",
    "\n",
    "display(result_df.style.format(\"{:,}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación de tabla 'summary_metals'\n",
    "\n",
    "col = ['metal', \n",
    "           'rougher.input.feed',         # materia prima\n",
    "           'rougher.output.concentrate', # concentrado rougher\n",
    "           'final.output.concentrate']   # concentrado final\n",
    "\n",
    "summary_metals = pd.DataFrame(columns=col).set_index(keys=['metal'])\n",
    "summary_metals\n",
    "\n",
    "# Suma de totales por etapa\n",
    "\n",
    "au_total = concentration_clean[['rougher.input.feed_au', 'rougher.output.concentrate_au', 'final.output.concentrate_au']].sum().round(2)\n",
    "ag_total = concentration_clean[['rougher.input.feed_ag', 'rougher.output.concentrate_ag', 'final.output.concentrate_ag']].sum().round(2)\n",
    "pb_total = concentration_clean[['rougher.input.feed_pb', 'rougher.output.concentrate_pb', 'final.output.concentrate_pb']].sum().round(2)\n",
    "\n",
    "# Incorporación de totales en tabla 'summary_metals'\n",
    "\n",
    "summary_metals.loc['Oro'] = {'rougher.input.feed': au_total[0],\n",
    "                              'rougher.output.concentrate': au_total[1], \n",
    "                              'final.output.concentrate': au_total[2]}\n",
    "\n",
    "summary_metals.loc['Plata'] = {'rougher.input.feed': ag_total[0],\n",
    "                                'rougher.output.concentrate': ag_total[1], \n",
    "                                'final.output.concentrate': ag_total[2]}\n",
    "\n",
    "summary_metals.loc['Plomo'] = {'rougher.input.feed': pb_total[0],\n",
    "                              'rougher.output.concentrate': pb_total[1], \n",
    "                              'final.output.concentrate': pb_total[2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de resultados\n",
    "\n",
    "summary_metals.plot(kind='bar', rot=0, ec='black')\n",
    "plt.title('Total de metales por etapa')\n",
    "plt.show()\n",
    "\n",
    "display(summary_metals.style.format(\"{:,.2f}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La concentración de **oro** muestra un **incremento sustancial** a lo largo del proceso, pasando de 142,784.42 en la alimentación inicial a 754,426.49 en el concentrado final. Esto indica una eficiente recuperación y enriquecimiento del oro durante las etapas de procesamiento, multiplicando aproximadamente por 5 la concentración inicial.\n",
    "\n",
    "El **plomo** también **incrementa su concentración de forma significativa**, casi triplicando su cantidad desde la alimentación inicial (61,387.48) hasta el concentrado final (171,101.74). Esto indica que el proceso es efectivo para concentrar plomo, aunque en menor magnitud comparado con el oro.\n",
    "\n",
    "La **plata** presenta un comportamiento distinto: aunque aumenta en la etapa intermedia (de 151,278.33 a 208,724.98), su **concentración disminuye notablemente** en el concentrado final (88,738.28). Esto podría sugerir pérdidas o separación selectiva de plata en etapas finales, o que parte de la plata se desvía hacia otros productos o residuos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construcción de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones para el cálculo del *sMAPE* y el *sMAPE final*\n",
    "\n",
    "Antes de construir y entrenar los modelos, es necesario definir una función que calcule la métrica de evaluación sMAPE. El sMAPE se calcula según la siguiente fórmula:\n",
    "\n",
    "$\\text{sMAPE} = {1 \\over n} \\displaystyle\\sum_{i=1}^{n} {{|y_i - \\hat{y_i}|} \\over {(|y_i| + |\\hat{y_i}|)/2}} \\times 100\\%$\n",
    "- $y_i$: Valor del objetivo para la observación con el índice $i$ en el conjunto utilizado para medir la calidad\n",
    "- $\\hat{y_i}$: Valor de la predicción para la observación con el índice $i$\n",
    "- $n$: Número de observaciones de la muestra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de sMAPE\n",
    "\n",
    "def smape(actual, predict):\n",
    "    return 100*(np.abs(actual - predict) / ((np.abs(actual) + np.abs(predict))/2)).mean()\n",
    "\n",
    "smape_score = met.make_scorer(smape, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para facilitar el cálculo de la métrica final, definiremos la función `final_smape`:\n",
    "\n",
    "$\\text{sMAPE final} = 25\\% \\times \\text{sMAPE(rougher)} + 75\\% \\times \\text{sMAPE(final)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de sMAPE final\n",
    "\n",
    "def final_smape(rougher, final):\n",
    "    return (0.25 * rougher) + (0.75 * final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección de características y objetivos\n",
    "\n",
    "A continuación, procederemos a preparar los conjuntos de entrenamiento y prueba, separando en ambos los objetivos `'rougher.output.recovery'` y `'final.output.recovery'`. Para ello, construiremos el conjunto de entrenamiento a partir del df `'data_train_clean'` y el conjunto de prueba a partir de `'data_test_clean'`, ambos conteniendo datos depurados y preparados para el modelado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conjuntos de entrenamiento\n",
    "\n",
    "features_train = data_train_clean.drop(['date', 'rougher.output.recovery', 'final.output.recovery'], axis=1)\n",
    "target_rougher_train = data_train_clean['rougher.output.recovery']\n",
    "target_final_train = data_train_clean['final.output.recovery']\n",
    "\n",
    "# Conjuntos de prueba\n",
    "features_test = data_test_clean.drop(['date', 'rougher.output.recovery', 'final.output.recovery'], axis=1)\n",
    "target_rougher_test = data_test_clean['rougher.output.recovery']\n",
    "target_final_test = data_test_clean['final.output.recovery']\n",
    "\n",
    "# Conjuntos de entrenamiento resumidos\n",
    "\n",
    "X = features_train\n",
    "Y = [target_rougher_train,\n",
    "     target_final_train]\n",
    "\n",
    "# Tabla de formas de los conjuntos\n",
    "\n",
    "data_dict = {\n",
    "    'Conjuntos de entrenamiento': [features_train.shape, len(target_rougher_train), len(target_final_train)],\n",
    "    'Conjuntos de prueba': [features_test.shape, len(target_rougher_test), len(target_final_test)]\n",
    "}\n",
    "\n",
    "new_dfs = pd.DataFrame(data_dict, index=['Observaciones', 'Objetivo \"rougher\"', 'Objetivo \"final\"'])\n",
    "\n",
    "display(new_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se entrenarán y ajustarán los modelos `DecisionTreeRegressor`, `RandomForestRegressor` y `LinearRegression` con el objetivo de optimizar sus parámetros y obtener las mejores puntuaciones posibles, buscando minimizar el error. Estos modelos serán comparados contra un modelo `Dummy`, que servirá como referencia básica para validar la efectividad y sanidad de los resultados obtenidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación de tabla para guardar resultados\n",
    "columns = ['sMAPE_rougher', 'sMAPE_final', 'sMAPE Final']\n",
    "indexes = ['DecisionTreeRegressor', 'RandomForestRegressor', 'LinearRegression', 'Dummy']\n",
    "\n",
    "sumario = pd.DataFrame(columns=columns, index=indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Modelo DecisionTreeRegressor\n",
    "\n",
    "for y in Y:\n",
    "    best_score = float('inf')\n",
    "    print(f'Predicción para \"{y.name}\"')\n",
    "\n",
    "    for depth in range(10, 20):\n",
    "        model = DecisionTreeRegressor(random_state=12345, max_depth=depth)\n",
    "        scores = cross_val_score(model, X, y, cv=5, scoring=smape_score)\n",
    "        mean_score = -1 * scores.mean()\n",
    "    \n",
    "        if mean_score < best_score:\n",
    "            best_score = mean_score\n",
    "            best_model = model.fit(X, y)\n",
    "    \n",
    "    # Print the best model and score only once after the loop\n",
    "    print('Mejor modelo:', best_model)\n",
    "    print(f'Puntuación: {best_score:.2f}\\n')\n",
    "    \n",
    "    # Guardado de resultados\n",
    "    if 'rougher' in y.name:\n",
    "        sumario.loc['DecisionTreeRegressor', 'sMAPE_rougher'] = round(best_score, 2)\n",
    "    else:\n",
    "        sumario.loc['DecisionTreeRegressor', 'sMAPE_final'] = round(best_score, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo RandomForestRegressor\n",
    "\n",
    "for y in Y:\n",
    "    best_score = float('inf')\n",
    "    print(f'Predicción para \"{y.name}\"')\n",
    "\n",
    "    for depth in range(10, 20):\n",
    "\n",
    "        model = RandomForestRegressor(random_state=12345, n_estimators=15, max_depth=depth)\n",
    "        scores = cross_val_score(model, X, y, cv=5, scoring=smape_score)\n",
    "        mean_score = -1 * scores.mean()\n",
    "    \n",
    "        if mean_score < best_score:\n",
    "            best_score = mean_score\n",
    "            best_model = model.fit(X, y)\n",
    "        \n",
    "    print('Mejor modelo:', best_model)\n",
    "    print(f'Puntuación: {best_score:.2f}\\n')\n",
    "     \n",
    "        # Guardado de resultados\n",
    "    if 'rougher' in y.name:\n",
    "        sumario.loc['RandomForestRegressor', 'sMAPE_rougher'] = round(best_score, 2)\n",
    "    else:\n",
    "        sumario.loc['RandomForestRegressor', 'sMAPE_final'] = round(best_score, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo \"LinearRegression\"\n",
    "\n",
    "for y in Y:\n",
    "    \n",
    "    print(f'Predicción para \"{y.name}\"')\n",
    "    model = LinearRegression()\n",
    "    scores = cross_val_score(model, X, y, cv=5, scoring=smape_score)\n",
    "    mean_score = -1 * scores.mean()\n",
    "    print(f'Puntuación: {mean_score:.2f}\\n')\n",
    "\n",
    "    model.fit(X, y)\n",
    "\n",
    "    # Guardado de resultados\n",
    "    if 'rougher' in y.name:\n",
    "        sumario.loc['LinearRegression', 'sMAPE_rougher'] = round(mean_score, 2)\n",
    "    else:\n",
    "        sumario.loc['LinearRegression', 'sMAPE_final'] = round(mean_score, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prueba de sanidad \"Dummy\"\n",
    "\n",
    "for y in Y:\n",
    "    \n",
    "    print(f'Predicción para \"{y.name}\"')\n",
    "    model = DummyRegressor(strategy='mean')\n",
    "    scores = cross_val_score(model, X, y, cv=3, scoring=smape_score)\n",
    "    mean_score = -1 * scores.mean()\n",
    "\n",
    "    print(f'Puntuación: {mean_score:.2f}\\n')\n",
    "\n",
    "    model.fit(X, y)\n",
    "\n",
    "    # Guardado de resultados\n",
    "    if 'rougher' in y.name:\n",
    "        sumario.loc['Dummy', 'sMAPE_rougher'] = round(mean_score, 2)\n",
    "    else:\n",
    "        sumario.loc['Dummy', 'sMAPE_final'] = round(mean_score, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculo de sMAPE Final\n",
    "sumario['sMAPE Final'] = final_smape(sumario['sMAPE_rougher'], sumario['sMAPE_final'])\n",
    "display(sumario)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La tabla muestra el desempeño comparativo de diferentes modelos de predicción evaluados mediante la métrica sMAPE en dos objetivos clave: `'rougher'` y `'final'`. El modelo `RandomForestRegressor` destaca por ofrecer los mejores resultados, con errores sMAPE significativamente menores (alrededor de 4.45%), lo que indica una mayor precisión y capacidad para capturar la complejidad de los datos. En contraste, el `DecisionTreeRegressor` y la `LinearRegression` presentan errores más altos, especialmente esta última en el objetivo final, lo que sugiere limitaciones para modelar las relaciones subyacentes. Finalmente, el modelo `Dummy`, que sirve como referencia básica, arroja los peores resultados, confirmando que los modelos entrenados aportan un valor predictivo real."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba del modelo elegido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de los hallazgos anteriores, se ha seleccionado el modelo `RandomForestRegressor` para ser aplicado sobre los conjuntos de prueba. El modelo se ajustará de manera individual conforme a los parámetros óptimos obtenidos previamente, con el fin de maximizar su rendimiento y asegurar una mejor capacidad de generalización al evaluarse con datos no vistos durante el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mejores modelos\n",
    "model_rougher = RandomForestRegressor(max_depth=17, n_estimators=15, random_state=12345)\n",
    "model_rougher.fit(X, target_rougher_train)\n",
    "\n",
    "model_final = RandomForestRegressor(max_depth=16, n_estimators=15, random_state=12345)\n",
    "model_final.fit(X, target_final_train)\n",
    "\n",
    "# Predicción de los objetivos de prueba\n",
    "\n",
    "prediction_rougher = model_rougher.predict(features_test)\n",
    "prediction_final = model_final.predict(features_test)\n",
    "\n",
    "# sMAPE para 'rougher' y 'final'\n",
    "rougher = smape(target_rougher_test, prediction_rougher)\n",
    "final = smape(target_final_test, prediction_final)\n",
    "\n",
    "# Cálculo de sMAPE Final\n",
    "final_smape_test = final_smape(rougher, final)\n",
    "\n",
    "# Tabla de resultados\n",
    "resultados = pd.DataFrame({\n",
    "    'Tipo': [\"smape 'rougher'\", \"smape 'final'\", \"smape FINAL\"],\n",
    "    'Puntuación': [rougher.round(2), final.round(2), final_smape_test.round(2)]})\n",
    "\n",
    "display(resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo `RandomForestRegressor` ha demostrado un desempeño sólido en la etapa de prueba, alcanzando un sMAPE final de aproximadamente 3.34%. Este bajo nivel de error relativo indica que las predicciones del modelo se ajustan con alta precisión a los valores reales, reflejando su capacidad para capturar las relaciones complejas presentes en los datos. Considerando la robustez inherente de Random Forest frente al ruido y su habilidad para modelar no linealidades, este resultado es alentador y sugiere que el modelo es adecuado para su aplicación en producción."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Se desarrolló un prototipo de modelo de Machine Learning para Zyfra con el objetivo de predecir la cantidad de oro extraído, utilizando datos de extracción y purificación para optimizar la producción y eliminar parámetros no rentables.\n",
    "\n",
    "- El análisis inicial confirmó que los datos son mayoritariamente numéricos. La columna `'date'` se convirtió a formato `datetime` para facilitar su manejo; además, se identificaron valores faltantes que fueron recuperados posteriormente.\n",
    "\n",
    "- La función desarrollada para calcular la recuperación del concentrado rougher mostró una precisión excelente, validando la calidad de los datos y la metodología empleada.\n",
    "\n",
    "- El análisis de concentraciones de metales evidenció que el proceso de purificación concentra eficazmente el oro y el plomo, mientras que la plata presenta un comportamiento distinto, sugiriendo posibles pérdidas o desviaciones en etapas finales.\n",
    "\n",
    "- La comparación entre los conjuntos de entrenamiento y prueba mostró distribuciones similares y tamaños adecuados, garantizando la representatividad y validez de la evaluación del modelo.\n",
    "\n",
    "- Se identificaron y eliminaron valores atípicos en las concentraciones de metales para evitar sesgos negativos en el modelado.\n",
    "\n",
    "- Tres modelos predictivos (`DecisionTreeRegressor`, `RandomForestRegressor` y `LinearRegression`) fueron entrenados y evaluados, destacando `RandomForestRegressor` por su mejor desempeño con un sMAPE cercano a 4.45%, superando ampliamente al modelo `Dummy`.\n",
    "\n",
    "- El modelo `RandomForestRegressor` fue seleccionado para la prueba final, donde demostró un rendimiento sólido con un sMAPE final de aproximadamente 3.34%, confirmando su capacidad para generalizar y su idoneidad para aplicación en producción.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
